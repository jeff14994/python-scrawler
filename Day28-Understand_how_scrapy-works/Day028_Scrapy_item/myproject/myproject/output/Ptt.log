2020-12-30 09:46:34 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: myproject)
2020-12-30 09:46:34 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Oct 19 2020, 16:00:31) - [Clang 11.0.3 (clang-1103.0.32.62)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform macOS-10.15.7-x86_64-i386-64bit
2020-12-30 09:46:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-12-30 09:46:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'myproject',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': './output/Ptt.log',
 'NEWSPIDER_MODULE': 'myproject.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['myproject.spiders']}
2020-12-30 09:46:34 [scrapy.extensions.telnet] INFO: Telnet Password: 7cbfa7af5ef7933d
2020-12-30 09:46:34 [py.warnings] WARNING: /usr/local/lib/python3.8/site-packages/scrapy/extensions/feedexport.py:247: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2020-12-30 09:46:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-12-30 09:46:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-12-30 09:46:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-12-30 09:46:34 [scrapy.middleware] INFO: Enabled item pipelines:
['myproject.pipelines.JSONPipeline']
2020-12-30 09:46:34 [scrapy.core.engine] INFO: Spider opened
2020-12-30 09:46:34 [PTTCrawler] DEBUG: Create temp file for store JSON - /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/.tmp.json.swp
2020-12-30 09:46:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-12-30 09:46:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-12-30 09:46:34 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ptt.cc/robots.txt> (referer: None)
2020-12-30 09:46:34 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ptt.cc/bbs/Gossiping/M.1557928779.A.0C1.html> (referer: None)
2020-12-30 09:46:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.ptt.cc/bbs/Gossiping/M.1557928779.A.0C1.html>: HTTP status code is not handled or not allowed
2020-12-30 09:46:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-12-30 09:46:34 [PTTCrawler] DEBUG: Save result at /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/20201230T09:46:34-20201230T09:46:34.json
2020-12-30 09:46:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 539,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 2407,
 'downloader/response_count': 2,
 'downloader/response_status_count/404': 2,
 'elapsed_time_seconds': 0.524444,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 12, 30, 1, 46, 34, 998739),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 4,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 53104640,
 'memusage/startup': 53104640,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 12, 30, 1, 46, 34, 474295)}
2020-12-30 09:46:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-12-30 09:54:18 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: myproject)
2020-12-30 09:54:18 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Oct 19 2020, 16:00:31) - [Clang 11.0.3 (clang-1103.0.32.62)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform macOS-10.15.7-x86_64-i386-64bit
2020-12-30 09:54:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-12-30 09:54:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'myproject',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': './output/Ptt.log',
 'NEWSPIDER_MODULE': 'myproject.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['myproject.spiders']}
2020-12-30 09:54:18 [scrapy.extensions.telnet] INFO: Telnet Password: f79220ed1ec83443
2020-12-30 09:54:18 [py.warnings] WARNING: /usr/local/lib/python3.8/site-packages/scrapy/extensions/feedexport.py:247: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2020-12-30 09:54:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-12-30 09:54:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-12-30 09:54:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-12-30 09:54:18 [scrapy.middleware] INFO: Enabled item pipelines:
['myproject.pipelines.JSONPipeline']
2020-12-30 09:54:18 [scrapy.core.engine] INFO: Spider opened
2020-12-30 09:54:18 [PTTCrawler] DEBUG: Create temp file for store JSON - /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/.tmp.json.swp
2020-12-30 09:54:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-12-30 09:54:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-12-30 09:54:18 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ptt.cc/robots.txt> (referer: None)
2020-12-30 09:54:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ptt.cc/bbs/movie/index.html> (referer: None)
2020-12-30 09:54:18 [py.warnings] WARNING: /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py:28: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 28 of the file /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(response.text)

2020-12-30 09:54:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ptt.cc/bbs/movie/index.html> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.8/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.8/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/usr/local/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.8/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.8/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.8/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/usr/local/lib/python3.8/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py", line 35, in parse
    metas = main_content.select('div.article-metaline')
AttributeError: 'NoneType' object has no attribute 'select'
2020-12-30 09:54:18 [scrapy.core.engine] INFO: Closing spider (finished)
2020-12-30 09:54:18 [PTTCrawler] DEBUG: Save result at /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/20201230T09:54:18-20201230T09:54:18.json
2020-12-30 09:54:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 522,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5413,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 0.569038,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 12, 30, 1, 54, 18, 771045),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'memusage/max': 53166080,
 'memusage/startup': 53166080,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 12, 30, 1, 54, 18, 202007)}
2020-12-30 09:54:18 [scrapy.core.engine] INFO: Spider closed (finished)
2020-12-30 09:56:58 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: myproject)
2020-12-30 09:56:58 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Oct 19 2020, 16:00:31) - [Clang 11.0.3 (clang-1103.0.32.62)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform macOS-10.15.7-x86_64-i386-64bit
2020-12-30 09:56:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-12-30 09:56:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'myproject',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': './output/Ptt.log',
 'NEWSPIDER_MODULE': 'myproject.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['myproject.spiders']}
2020-12-30 09:56:58 [scrapy.extensions.telnet] INFO: Telnet Password: f3b50782d76108d7
2020-12-30 09:56:58 [py.warnings] WARNING: /usr/local/lib/python3.8/site-packages/scrapy/extensions/feedexport.py:247: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2020-12-30 09:56:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-12-30 09:56:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-12-30 09:56:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-12-30 09:56:59 [scrapy.middleware] INFO: Enabled item pipelines:
['myproject.pipelines.JSONPipeline']
2020-12-30 09:56:59 [scrapy.core.engine] INFO: Spider opened
2020-12-30 09:56:59 [PTTCrawler] DEBUG: Create temp file for store JSON - /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/.tmp.json.swp
2020-12-30 09:56:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-12-30 09:56:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-12-30 09:56:59 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ptt.cc/robots.txt> (referer: None)
2020-12-30 09:56:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html> (referer: None)
2020-12-30 09:56:59 [py.warnings] WARNING: /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py:28: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 28 of the file /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(response.text)

2020-12-30 09:56:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html>
{'url': 'https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html', 'article_id': 'M.1609255595.A.50A', 'article_author': 'willyYu (威利魚)', 'article_title': '[好雷] 《孤味》觀後感', 'article_date': 'Tue Dec 29 23:26:32 2020', 'article_content': '各位大家好，我是威利魚~\n\n在朋友的推薦下，看了《孤味》這部國片，不僅翻轉了我對於國片的印象，更讓自己想起\n了自己外婆的故事。\n\n版上已經有很多精彩的心得文，小弟這邊想單純的分享《孤味》和我外婆的故事。\n\n文長，可以考慮圖文好讀版： https://tinyurl.com/ycl67vpz ~~~~~~~~~~~~~~~~~~~ 雷文 主文分隔線 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n首先我想分享我外婆的故事：\n\n我的外婆，從小對於她的印象就是講話很大聲。我的台語不輪轉，但能聽得懂八成阿嬤想\n跟我說的，但不知道是不是因為口音的關係，外婆想和我說的，我總是聽不明白。\n\n而我的外公，在我媽年紀還小時，就趁著跑船靠近美國時跳船上岸，換成現代的語言就是\n非法移民。想當然他需要想一個合法留在美國的辦法，所以他後來在美國和一個亞裔後代\n結婚拿到居留權。\n\n我小時候總是沒辦法明白，為什麼外公要去美國，或許外公覺得在美國能賺更多的錢養家\n，但為什麼？我聽我媽媽說她小時候也不明白，寫了好多的信去美國罵他都不回台灣。\n就在今年農曆年後沒多久，外婆因為感冒造成的肺積水，使得心臟不堪負荷，停止跳動，\n外婆腦缺氧暈了過去。其實這並不是外婆第一次暈倒，但之前的暈倒是因為外婆吃了降血\n糖藥後卻沒有吃飯，血糖過低而暈倒。\n\n而這次昏迷則不同外婆再也沒有醒來了。\n\n在幫外婆辦後事的時候我才知道，原來外婆和外公從來就沒有離婚，今年也因為疫情的關\n係，沒辦法說回台灣就回台灣，所以遺產方面處理起來也是格外的麻煩。\n\n說來也有趣，在處理外婆的遺物時，才發現外婆有一張十萬元左右的借據，也不知道借給\n誰，也不知道找誰討。\n\n在我的印象裡，外婆就是這樣刀子嘴豆腐心。\n\n\n以下涉及《孤味》劇透\n\n\n在看《孤味》的時候，陳淑芳飾演的林秀英，和我外婆好像、好像。總是很努力地過生活\n，總是很大聲的和家人說話，總是皺著眉頭不知道在想些甚麼。\n\n在《孤味》中，我最有印象的一段是兩個大女兒在調侃著媽媽，僅管爸爸外遇，還不是媽\n媽最愛爸爸，所以在爸爸回家時才會有小女兒出生。這段劇情，讓我想起我印象中唯二外\n公回來台灣的時候，我媽對我說：\n\n你看外婆的樣子，嘴巴上說哪裡都不想去，但還不是哪都去。\n\n《孤味》其中最有意思的橋段，莫過於是林秀英和蔡美林的碰面。林秀英知道蔡美林的住\n處後，氣沖沖地跑去台北想和她對質。而當林秀英知道蔡美林的手機號碼後，打電話過去\n，接通了，卻一句話都說不出來。最後在林秀英真的和蔡美林碰面後，不但一點都不生氣\n，還透過蔡美林知道了丈夫生前對於自己的事情到底是怎麼想的。而我也曾想過，若是我\n外婆和外公在美國的另一半見面了，她們究竟會說些甚麼呢？\n\n在《孤味》的結尾，林秀英才真正的簽了離婚協議書，隨著放在她一直都很珍藏的寶盒內\n，燒掉了。在處理我外婆的後事時，我也曾經想過，燒遺物意義到底何在？後來才領悟到\n，就如這段劇情所描述的，對於家屬而言，其實這就是一種放下。無論死者究竟和仍在世\n上的人有多少瓜葛，好像也就只能這麼算了  所以林秀英最後選擇用了那張她曾覺得\n不三不四的照片作為遺照，更讓蔡美林作為遺孀參加葬禮，而她則自己一個人在豪華計程\n車上唱著他們最愛的一首歌為自己的前夫送別。\n\n有人說《孤味》在美化外遇這件事，但我認為剛好相反。在那個年代，那個連女權這個詞\n都還不知道有沒有存在的年代，儘管已經沒有妻妾制度，但在那樣的過渡期，或許女性可\n能自己都認為該對男性一廂情願。《孤味》很好的拍出了這樣的故事，告訴不曾經歷過這\n段時光的人們，在台灣曾有女性是這樣對待過一段感情的；我們更應該為平權努力，不只\n是為了女性，而是告訴雙方，一段感情是屬於彼此的責任，並不應該如此重壓在其中一方\n，這樣的重擔，真的是直到死了才能放下。\n\n很謝謝導演用台南溫暖的色調敘述了《孤味》這樣的故事，\n\n有一點悲傷，從現代眼光看來荒唐，但卻真實存在過的故事。\n\n https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html', 'ip': '123.110.248.106', 'message_count': {'all': 3, 'count': 1, 'push': 2, 'boo': 1, 'neutral': 0}, 'messages': [{'push_tag': '推', 'push_userid': 'kellyho0830', 'push_content': '推推', 'push_ipdatetime': '12/29 23:33'}, {'push_tag': '推', 'push_userid': 'autumn06095', 'push_content': '推', 'push_ipdatetime': '12/29 23:41'}, {'push_tag': '噓', 'push_userid': 'butmyass', 'push_content': '板上 儘管', 'push_ipdatetime': '12/29 23:45'}]}
2020-12-30 09:56:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-12-30 09:56:59 [PTTCrawler] DEBUG: Save result at /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/20201230T09:56:59-20201230T09:56:59.json
2020-12-30 09:56:59 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: ./output/Ptt.json
2020-12-30 09:56:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 535,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 6141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 0.573334,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 12, 30, 1, 56, 59, 658435),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'memusage/max': 53116928,
 'memusage/startup': 53116928,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 12, 30, 1, 56, 59, 85101)}
2020-12-30 09:56:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-12-30 10:13:30 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: myproject)
2020-12-30 10:13:30 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Oct 19 2020, 16:00:31) - [Clang 11.0.3 (clang-1103.0.32.62)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform macOS-10.15.7-x86_64-i386-64bit
2020-12-30 10:13:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-12-30 10:13:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'myproject',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': './output/Ptt.log',
 'NEWSPIDER_MODULE': 'myproject.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['myproject.spiders']}
2020-12-30 10:13:30 [scrapy.extensions.telnet] INFO: Telnet Password: 1e5270aeb201888b
2020-12-30 10:13:30 [py.warnings] WARNING: /usr/local/lib/python3.8/site-packages/scrapy/extensions/feedexport.py:247: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2020-12-30 10:13:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-12-30 10:13:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-12-30 10:13:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-12-30 10:13:30 [scrapy.middleware] INFO: Enabled item pipelines:
['myproject.pipelines.JSONPipeline']
2020-12-30 10:13:30 [scrapy.core.engine] INFO: Spider opened
2020-12-30 10:13:30 [PTTCrawler] DEBUG: Create temp file for store JSON - /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/.tmp.json.swp
2020-12-30 10:13:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-12-30 10:13:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-12-30 10:13:30 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ptt.cc/robots.txt> (referer: None)
2020-12-30 10:13:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html> (referer: None)
2020-12-30 10:13:31 [py.warnings] WARNING: /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py:28: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 28 of the file /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(response.text)

2020-12-30 10:13:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html>
{'url': 'https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html', 'article_id': 'M.1609255595.A.50A', 'article_author': 'willyYu (威利魚)', 'article_title': '[好雷] 《孤味》觀後感', 'article_date': 'Tue Dec 29 23:26:32 2020', 'article_content': '各位大家好，我是威利魚~\n\n在朋友的推薦下，看了《孤味》這部國片，不僅翻轉了我對於國片的印象，更讓自己想起\n了自己外婆的故事。\n\n版上已經有很多精彩的心得文，小弟這邊想單純的分享《孤味》和我外婆的故事。\n\n文長，可以考慮圖文好讀版： https://tinyurl.com/ycl67vpz ~~~~~~~~~~~~~~~~~~~ 雷文 主文分隔線 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n首先我想分享我外婆的故事：\n\n我的外婆，從小對於她的印象就是講話很大聲。我的台語不輪轉，但能聽得懂八成阿嬤想\n跟我說的，但不知道是不是因為口音的關係，外婆想和我說的，我總是聽不明白。\n\n而我的外公，在我媽年紀還小時，就趁著跑船靠近美國時跳船上岸，換成現代的語言就是\n非法移民。想當然他需要想一個合法留在美國的辦法，所以他後來在美國和一個亞裔後代\n結婚拿到居留權。\n\n我小時候總是沒辦法明白，為什麼外公要去美國，或許外公覺得在美國能賺更多的錢養家\n，但為什麼？我聽我媽媽說她小時候也不明白，寫了好多的信去美國罵他都不回台灣。\n就在今年農曆年後沒多久，外婆因為感冒造成的肺積水，使得心臟不堪負荷，停止跳動，\n外婆腦缺氧暈了過去。其實這並不是外婆第一次暈倒，但之前的暈倒是因為外婆吃了降血\n糖藥後卻沒有吃飯，血糖過低而暈倒。\n\n而這次昏迷則不同外婆再也沒有醒來了。\n\n在幫外婆辦後事的時候我才知道，原來外婆和外公從來就沒有離婚，今年也因為疫情的關\n係，沒辦法說回台灣就回台灣，所以遺產方面處理起來也是格外的麻煩。\n\n說來也有趣，在處理外婆的遺物時，才發現外婆有一張十萬元左右的借據，也不知道借給\n誰，也不知道找誰討。\n\n在我的印象裡，外婆就是這樣刀子嘴豆腐心。\n\n\n以下涉及《孤味》劇透\n\n\n在看《孤味》的時候，陳淑芳飾演的林秀英，和我外婆好像、好像。總是很努力地過生活\n，總是很大聲的和家人說話，總是皺著眉頭不知道在想些甚麼。\n\n在《孤味》中，我最有印象的一段是兩個大女兒在調侃著媽媽，僅管爸爸外遇，還不是媽\n媽最愛爸爸，所以在爸爸回家時才會有小女兒出生。這段劇情，讓我想起我印象中唯二外\n公回來台灣的時候，我媽對我說：\n\n你看外婆的樣子，嘴巴上說哪裡都不想去，但還不是哪都去。\n\n《孤味》其中最有意思的橋段，莫過於是林秀英和蔡美林的碰面。林秀英知道蔡美林的住\n處後，氣沖沖地跑去台北想和她對質。而當林秀英知道蔡美林的手機號碼後，打電話過去\n，接通了，卻一句話都說不出來。最後在林秀英真的和蔡美林碰面後，不但一點都不生氣\n，還透過蔡美林知道了丈夫生前對於自己的事情到底是怎麼想的。而我也曾想過，若是我\n外婆和外公在美國的另一半見面了，她們究竟會說些甚麼呢？\n\n在《孤味》的結尾，林秀英才真正的簽了離婚協議書，隨著放在她一直都很珍藏的寶盒內\n，燒掉了。在處理我外婆的後事時，我也曾經想過，燒遺物意義到底何在？後來才領悟到\n，就如這段劇情所描述的，對於家屬而言，其實這就是一種放下。無論死者究竟和仍在世\n上的人有多少瓜葛，好像也就只能這麼算了  所以林秀英最後選擇用了那張她曾覺得\n不三不四的照片作為遺照，更讓蔡美林作為遺孀參加葬禮，而她則自己一個人在豪華計程\n車上唱著他們最愛的一首歌為自己的前夫送別。\n\n有人說《孤味》在美化外遇這件事，但我認為剛好相反。在那個年代，那個連女權這個詞\n都還不知道有沒有存在的年代，儘管已經沒有妻妾制度，但在那樣的過渡期，或許女性可\n能自己都認為該對男性一廂情願。《孤味》很好的拍出了這樣的故事，告訴不曾經歷過這\n段時光的人們，在台灣曾有女性是這樣對待過一段感情的；我們更應該為平權努力，不只\n是為了女性，而是告訴雙方，一段感情是屬於彼此的責任，並不應該如此重壓在其中一方\n，這樣的重擔，真的是直到死了才能放下。\n\n很謝謝導演用台南溫暖的色調敘述了《孤味》這樣的故事，\n\n有一點悲傷，從現代眼光看來荒唐，但卻真實存在過的故事。\n\n https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html', 'ip': '123.110.248.106', 'message_count': {'all': 3, 'count': 1, 'push': 2, 'boo': 1, 'neutral': 0}, 'messages': [{'push_tag': '推', 'push_userid': 'kellyho0830', 'push_content': '推推', 'push_ipdatetime': '12/29 23:33'}, {'push_tag': '推', 'push_userid': 'autumn06095', 'push_content': '推', 'push_ipdatetime': '12/29 23:41'}, {'push_tag': '噓', 'push_userid': 'butmyass', 'push_content': '板上 儘管', 'push_ipdatetime': '12/29 23:45'}]}
2020-12-30 10:13:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ptt.cc/bbs/movie/M.1609257932.A.2ED.html> (referer: None)
2020-12-30 10:13:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.ptt.cc/bbs/movie/M.1609257932.A.2ED.html>
{'url': 'https://www.ptt.cc/bbs/movie/M.1609257932.A.2ED.html', 'article_id': 'M.1609257932.A.2ED', 'article_author': 'CYKONGG (XXX)', 'article_title': '[新聞] 喬瑟夫高登李維據傳和漫威聯繫！「驚奇4', 'article_date': 'Wed Dec 30 00:05:25 2020', 'article_content': '喬瑟夫高登李維據傳和漫威工作室聯繫爆料者表示：可能與《驚奇4超人》重啟版有關 https://i.imgur.com/nCvsziC.jpg 眾星紛紛加入漫威，下一個會是誰？\n在漫威電影宇宙發展多年下來，不僅捧紅了許多演員，不少本來就有著一定名氣的大咖也\n都陸續加入這個系列，無論是成為班底或是一次性的演出，即使是在《復仇者聯盟：終局\n之戰》這部階段性的集大成之作推出，並且正式進入了第四階段後，這個現象也完全沒有\n停下來的跡象。而在安潔莉娜裘莉和克里斯汀貝爾紛紛宣布即將加盟這個仍然持續成長中\n的系列後，最新傳聞又暗示了喬瑟夫高登李維 (Joseph GordonLevitt) 可能已經與漫威\n工作室取得了聯繫。\n\n\n在這之前，喬瑟夫高登李維曾經演出過克里斯多福諾蘭執導的《全面啟動》以及《黑暗騎\n士：黎明升起》，他在後者中飾演了片尾揭露別名為羅賓的約翰布雷克警探。除了《\n黑暗騎士：黎明升起》之外，這位演員還曾經在另一部漫畫改編作品《萬惡城市：紅顏奪\n命》中飾演賭徒強尼，之後也參與了2020年的Netflix電影《超能計畫》。值得一提的是\n，喬瑟夫高登李維也曾親自執導過2013年的《超急情聖》，並找來了史嘉蕾喬韓森主演。 https://i.imgur.com/5C1RlcV.jpg 根據內線消息爆料者Charles Murphy的說法，喬瑟夫高登李維最近已經與至少一位來自凱\n文費吉旗下漫威工作室中的創意團隊成員取得過聯繫。但目前仍然無法確定這次的聯繫所\n談論的是潛在的角色演出邀約，或是加入幕後團隊的可能性。 https://i.imgur.com/Yl38SMW.jpg 有趣的是，這也並非喬瑟夫高登李維第一次傳出可能將要加入漫威系列的傳聞。近年來曾\n經有傳聞暗示將要由這位演員演出的角色包含了《星際異攻隊》的星爵、《蟻人》的史考\n特朗恩以及《奇異博士》的史蒂芬史傳奇，但這三位角色最終分別由克里斯普瑞特、保羅\n路德，以及班尼狄克康柏拜區飾演。\n\n\n即使多年下來一直有傳聞暗示諾蘭的蝙蝠俠宇宙在《黑暗騎士：黎明升起》之後可能將會\n由喬瑟夫高登李維繼續主演下去，但DC始終沒有證實相關的計畫。就在今年稍早，喬瑟夫\n高登李維在Reddit論壇的問答活動中提到他非常喜歡諾蘭《蝙蝠俠》三部曲的收尾方式。 https://i.imgur.com/mmAFIeC.jpg 爆料者Charles Murphy認為喬瑟夫高登李維與漫威的聯繫可能與《驚奇4超人》的重啟版\n本有關，這部讓粉絲們期待已久的新版本也已經在本月稍早的迪士尼投資者日上由凱文費\n吉本人親自揭露，並證實了將會由漫威版《蜘蛛人》三部曲導演強華茲負責執導，至於演\n員的部分則尚未公開。 https://i.imgur.com/97oE9bw.jpg 在這場最新的公開活動上，漫威工作室也揭露了第三部《蟻人》和《星際異攻隊》以及《\n驚奇隊長》續集的消息，以及預計的上映日期。至於未公開發行日期的則包含了《驚奇4\n超人》重啟版、馬赫夏拉阿里主演的《刀鋒戰士》重啟版，以及《月光騎士》、《女浩克\n》，再加上首度公開的《秘密入侵》(Secret Invasion)、《鋼鐵心》(Ironheart) 以及\n《裝甲戰爭》(Armor Wars)。 https://i.imgur.com/nzm2LuL.jpg 至於喬瑟夫高登李維，他的最新作品《7500》目前也正在Amazon Prime平台上熱播中，最\n近也演出了Netflix好評電影《芝加哥七人案：驚世審判》。而漫威工作室接下來的作品\n包含了將於2021年1月15日上線的《汪達與幻視》(WandaVision) 和5月7日的《黑寡婦》(\nBlack Widow)。 https://reurl.cc/8nQrQM 《汪達與幻視》最新短版預告： https://youtu.be/SntsSsMLUWA https://www.ptt.cc/bbs/movie/M.1609257932.A.2ED.html', 'ip': '49.216.129.155', 'message_count': {'all': 34, 'count': 24, 'push': 25, 'boo': 1, 'neutral': 8}, 'messages': [{'push_tag': '推', 'push_userid': 'aure0914', 'push_content': '想看他演羅賓', 'push_ipdatetime': '12/30 00:13'}, {'push_tag': '推', 'push_userid': 'REI3173', 'push_content': '慷仁', 'push_ipdatetime': '12/30 00:15'}, {'push_tag': '→', 'push_userid': 'uhawae', 'push_content': '還    蠻     屌     的      屌            爆', 'push_ipdatetime': '12/30 00:25'}, {'push_tag': '推', 'push_userid': 'alwaysstrong', 'push_content': '是要找他演李德？', 'push_ipdatetime': '12/30 00:34'}, {'push_tag': '推', 'push_userid': 'BleedWang', 'push_content': '他不夠狂 不可能演霹靂火 應該是演橡膠人無誤', 'push_ipdatetime': '12/30 00:36'}, {'push_tag': '→', 'push_userid': 'BleedWang', 'push_content': '但也有可能是石頭人啦', 'push_ipdatetime': '12/30 00:37'}, {'push_tag': '→', 'push_userid': 'takuminauki', 'push_content': '過氣二線', 'push_ipdatetime': '12/30 00:48'}, {'push_tag': '推', 'push_userid': 'BLUEPAPER', 'push_content': '不要再重啟了 根本浪費好演員', 'push_ipdatetime': '12/30 00:53'}, {'push_tag': '推', 'push_userid': 'kowei526', 'push_content': '想看他演羅賓+1 諾蘭都鋪好路了><', 'push_ipdatetime': '12/30 01:00'}, {'push_tag': '推', 'push_userid': 'alvis000', 'push_content': '我喜歡看他演戲', 'push_ipdatetime': '12/30 01:14'}, {'push_tag': '推', 'push_userid': 'd19901023', 'push_content': '結果是末日博士', 'push_ipdatetime': '12/30 01:26'}, {'push_tag': '推', 'push_userid': 'lucifax', 'push_content': '直接找吳慷仁比較快', 'push_ipdatetime': '12/30 01:26'}, {'push_tag': '→', 'push_userid': 'BoyoRo', 'push_content': '搞不好演隱形女啊', 'push_ipdatetime': '12/30 01:28'}, {'push_tag': '→', 'push_userid': 'MK47', 'push_content': '完全不會想看= =', 'push_ipdatetime': '12/30 02:00'}, {'push_tag': '噓', 'push_userid': 'Sk8erBoi', 'push_content': '.', 'push_ipdatetime': '12/30 02:58'}, {'push_tag': '推', 'push_userid': 'lost0816', 'push_content': '他的羅賓太棒，那個升起的結局，成為他演員最棒鏡頭', 'push_ipdatetime': '12/30 03:33'}, {'push_tag': '推', 'push_userid': 'Eddward', 'push_content': '是不是要開賭盤看這次4個哪個變黑人', 'push_ipdatetime': '12/30 03:51'}, {'push_tag': '推', 'push_userid': 'egg781', 'push_content': '不拍MCU版驚奇四超人你是要怎麼引入地獄博士,而且里', 'push_ipdatetime': '12/30 06:36'}, {'push_tag': '→', 'push_userid': 'egg781', 'push_content': '德還有搞砸揹鍋的作用', 'push_ipdatetime': '12/30 06:36'}, {'push_tag': '推', 'push_userid': 'lpb', 'push_content': '樓上，Dr.Doom應該是末日博士吧？XD', 'push_ipdatetime': '12/30 07:28'}, {'push_tag': '→', 'push_userid': 'lpb', 'push_content': '猜他應該是出演里德？', 'push_ipdatetime': '12/30 07:29'}, {'push_tag': '推', 'push_userid': 'sunsirr', 'push_content': '他之前演羅賓很適合，身材又好', 'push_ipdatetime': '12/30 07:40'}, {'push_tag': '推', 'push_userid': 'egg781', 'push_content': '更正末日博士,感謝', 'push_ipdatetime': '12/30 07:59'}, {'push_tag': '推', 'push_userid': 'litann4', 'push_content': '覺得他很帥', 'push_ipdatetime': '12/30 08:02'}, {'push_tag': '推', 'push_userid': 'peterw', 'push_content': '反而想看他演霹靂火耶，他看起來不夠聰明演李德', 'push_ipdatetime': '12/30 08:24'}, {'push_tag': '→', 'push_userid': 'wjack29', 'push_content': '美隊回鍋演霹靂火', 'push_ipdatetime': '12/30 08:29'}, {'push_tag': '推', 'push_userid': 'buwa56', 'push_content': '羅賓+1', 'push_ipdatetime': '12/30 08:33'}, {'push_tag': '推', 'push_userid': 'notea', 'push_content': '演李德或DOOM不錯阿', 'push_ipdatetime': '12/30 08:44'}, {'push_tag': '推', 'push_userid': 'FRX', 'push_content': '好喝到妹噗茶', 'push_ipdatetime': '12/30 08:51'}, {'push_tag': '推', 'push_userid': 'luke417', 'push_content': '美國吳慷仁', 'push_ipdatetime': '12/30 08:54'}, {'push_tag': '推', 'push_userid': 'maxiiiii', 'push_content': '他可以', 'push_ipdatetime': '12/30 09:01'}, {'push_tag': '推', 'push_userid': 'rinsoukan', 'push_content': '想看他演羅賓', 'push_ipdatetime': '12/30 09:15'}, {'push_tag': '推', 'push_userid': 'gogolamingo', 'push_content': '標題看成李登輝', 'push_ipdatetime': '12/30 10:05'}, {'push_tag': '推', 'push_userid': 'isislove', 'push_content': '小希斯～', 'push_ipdatetime': '12/30 10:11'}]}
2020-12-30 10:13:31 [scrapy.core.engine] INFO: Closing spider (finished)
2020-12-30 10:13:31 [PTTCrawler] DEBUG: Save result at /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/20201230T10:13:30-20201230T10:13:31.json
2020-12-30 10:13:31 [scrapy.extensions.feedexport] INFO: Stored json feed (2 items) in: ./output/Ptt.json
2020-12-30 10:13:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 850,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 12408,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 0.727028,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 12, 30, 2, 13, 31, 292833),
 'item_scraped_count': 2,
 'log_count/DEBUG': 7,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'memusage/max': 53104640,
 'memusage/startup': 53104640,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2020, 12, 30, 2, 13, 30, 565805)}
2020-12-30 10:13:31 [scrapy.core.engine] INFO: Spider closed (finished)
2020-12-30 10:14:17 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: myproject)
2020-12-30 10:14:17 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.8.6 (default, Oct 19 2020, 16:00:31) - [Clang 11.0.3 (clang-1103.0.32.62)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform macOS-10.15.7-x86_64-i386-64bit
2020-12-30 10:14:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-12-30 10:14:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'myproject',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': './output/Ptt.log',
 'NEWSPIDER_MODULE': 'myproject.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['myproject.spiders']}
2020-12-30 10:14:17 [scrapy.extensions.telnet] INFO: Telnet Password: 0bd5a681f783bf32
2020-12-30 10:14:17 [py.warnings] WARNING: /usr/local/lib/python3.8/site-packages/scrapy/extensions/feedexport.py:247: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2020-12-30 10:14:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2020-12-30 10:14:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-12-30 10:14:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-12-30 10:14:17 [scrapy.middleware] INFO: Enabled item pipelines:
['myproject.pipelines.JSONPipeline']
2020-12-30 10:14:17 [scrapy.core.engine] INFO: Spider opened
2020-12-30 10:14:17 [PTTCrawler] DEBUG: Create temp file for store JSON - /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/.tmp.json.swp
2020-12-30 10:14:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-12-30 10:14:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-12-30 10:14:17 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ptt.cc/robots.txt> (referer: None)
2020-12-30 10:14:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html> (referer: None)
2020-12-30 10:14:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ptt.cc/bbs/movie/M.1609257932.A.2ED.html> (referer: None)
2020-12-30 10:14:18 [py.warnings] WARNING: /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py:28: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

The code that caused this warning is on line 28 of the file /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/myproject/spiders/PTTCrawler.py. To get rid of this warning, pass the additional argument 'features="lxml"' to the BeautifulSoup constructor.

  soup = BeautifulSoup(response.text)

2020-12-30 10:14:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html>
{'url': 'https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html', 'article_id': 'M.1609255595.A.50A', 'article_author': 'willyYu (威利魚)', 'article_title': '[好雷] 《孤味》觀後感', 'article_date': 'Tue Dec 29 23:26:32 2020', 'article_content': '各位大家好，我是威利魚~\n\n在朋友的推薦下，看了《孤味》這部國片，不僅翻轉了我對於國片的印象，更讓自己想起\n了自己外婆的故事。\n\n版上已經有很多精彩的心得文，小弟這邊想單純的分享《孤味》和我外婆的故事。\n\n文長，可以考慮圖文好讀版： https://tinyurl.com/ycl67vpz ~~~~~~~~~~~~~~~~~~~ 雷文 主文分隔線 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n首先我想分享我外婆的故事：\n\n我的外婆，從小對於她的印象就是講話很大聲。我的台語不輪轉，但能聽得懂八成阿嬤想\n跟我說的，但不知道是不是因為口音的關係，外婆想和我說的，我總是聽不明白。\n\n而我的外公，在我媽年紀還小時，就趁著跑船靠近美國時跳船上岸，換成現代的語言就是\n非法移民。想當然他需要想一個合法留在美國的辦法，所以他後來在美國和一個亞裔後代\n結婚拿到居留權。\n\n我小時候總是沒辦法明白，為什麼外公要去美國，或許外公覺得在美國能賺更多的錢養家\n，但為什麼？我聽我媽媽說她小時候也不明白，寫了好多的信去美國罵他都不回台灣。\n就在今年農曆年後沒多久，外婆因為感冒造成的肺積水，使得心臟不堪負荷，停止跳動，\n外婆腦缺氧暈了過去。其實這並不是外婆第一次暈倒，但之前的暈倒是因為外婆吃了降血\n糖藥後卻沒有吃飯，血糖過低而暈倒。\n\n而這次昏迷則不同外婆再也沒有醒來了。\n\n在幫外婆辦後事的時候我才知道，原來外婆和外公從來就沒有離婚，今年也因為疫情的關\n係，沒辦法說回台灣就回台灣，所以遺產方面處理起來也是格外的麻煩。\n\n說來也有趣，在處理外婆的遺物時，才發現外婆有一張十萬元左右的借據，也不知道借給\n誰，也不知道找誰討。\n\n在我的印象裡，外婆就是這樣刀子嘴豆腐心。\n\n\n以下涉及《孤味》劇透\n\n\n在看《孤味》的時候，陳淑芳飾演的林秀英，和我外婆好像、好像。總是很努力地過生活\n，總是很大聲的和家人說話，總是皺著眉頭不知道在想些甚麼。\n\n在《孤味》中，我最有印象的一段是兩個大女兒在調侃著媽媽，僅管爸爸外遇，還不是媽\n媽最愛爸爸，所以在爸爸回家時才會有小女兒出生。這段劇情，讓我想起我印象中唯二外\n公回來台灣的時候，我媽對我說：\n\n你看外婆的樣子，嘴巴上說哪裡都不想去，但還不是哪都去。\n\n《孤味》其中最有意思的橋段，莫過於是林秀英和蔡美林的碰面。林秀英知道蔡美林的住\n處後，氣沖沖地跑去台北想和她對質。而當林秀英知道蔡美林的手機號碼後，打電話過去\n，接通了，卻一句話都說不出來。最後在林秀英真的和蔡美林碰面後，不但一點都不生氣\n，還透過蔡美林知道了丈夫生前對於自己的事情到底是怎麼想的。而我也曾想過，若是我\n外婆和外公在美國的另一半見面了，她們究竟會說些甚麼呢？\n\n在《孤味》的結尾，林秀英才真正的簽了離婚協議書，隨著放在她一直都很珍藏的寶盒內\n，燒掉了。在處理我外婆的後事時，我也曾經想過，燒遺物意義到底何在？後來才領悟到\n，就如這段劇情所描述的，對於家屬而言，其實這就是一種放下。無論死者究竟和仍在世\n上的人有多少瓜葛，好像也就只能這麼算了  所以林秀英最後選擇用了那張她曾覺得\n不三不四的照片作為遺照，更讓蔡美林作為遺孀參加葬禮，而她則自己一個人在豪華計程\n車上唱著他們最愛的一首歌為自己的前夫送別。\n\n有人說《孤味》在美化外遇這件事，但我認為剛好相反。在那個年代，那個連女權這個詞\n都還不知道有沒有存在的年代，儘管已經沒有妻妾制度，但在那樣的過渡期，或許女性可\n能自己都認為該對男性一廂情願。《孤味》很好的拍出了這樣的故事，告訴不曾經歷過這\n段時光的人們，在台灣曾有女性是這樣對待過一段感情的；我們更應該為平權努力，不只\n是為了女性，而是告訴雙方，一段感情是屬於彼此的責任，並不應該如此重壓在其中一方\n，這樣的重擔，真的是直到死了才能放下。\n\n很謝謝導演用台南溫暖的色調敘述了《孤味》這樣的故事，\n\n有一點悲傷，從現代眼光看來荒唐，但卻真實存在過的故事。\n\n https://www.ptt.cc/bbs/movie/M.1609255595.A.50A.html', 'ip': '123.110.248.106', 'message_count': {'all': 3, 'count': 1, 'push': 2, 'boo': 1, 'neutral': 0}, 'messages': [{'push_tag': '推', 'push_userid': 'kellyho0830', 'push_content': '推推', 'push_ipdatetime': '12/29 23:33'}, {'push_tag': '推', 'push_userid': 'autumn06095', 'push_content': '推', 'push_ipdatetime': '12/29 23:41'}, {'push_tag': '噓', 'push_userid': 'butmyass', 'push_content': '板上 儘管', 'push_ipdatetime': '12/29 23:45'}]}
2020-12-30 10:14:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.ptt.cc/bbs/movie/M.1609257932.A.2ED.html>
{'url': 'https://www.ptt.cc/bbs/movie/M.1609257932.A.2ED.html', 'article_id': 'M.1609257932.A.2ED', 'article_author': 'CYKONGG (XXX)', 'article_title': '[新聞] 喬瑟夫高登李維據傳和漫威聯繫！「驚奇4', 'article_date': 'Wed Dec 30 00:05:25 2020', 'article_content': '喬瑟夫高登李維據傳和漫威工作室聯繫爆料者表示：可能與《驚奇4超人》重啟版有關 https://i.imgur.com/nCvsziC.jpg 眾星紛紛加入漫威，下一個會是誰？\n在漫威電影宇宙發展多年下來，不僅捧紅了許多演員，不少本來就有著一定名氣的大咖也\n都陸續加入這個系列，無論是成為班底或是一次性的演出，即使是在《復仇者聯盟：終局\n之戰》這部階段性的集大成之作推出，並且正式進入了第四階段後，這個現象也完全沒有\n停下來的跡象。而在安潔莉娜裘莉和克里斯汀貝爾紛紛宣布即將加盟這個仍然持續成長中\n的系列後，最新傳聞又暗示了喬瑟夫高登李維 (Joseph GordonLevitt) 可能已經與漫威\n工作室取得了聯繫。\n\n\n在這之前，喬瑟夫高登李維曾經演出過克里斯多福諾蘭執導的《全面啟動》以及《黑暗騎\n士：黎明升起》，他在後者中飾演了片尾揭露別名為羅賓的約翰布雷克警探。除了《\n黑暗騎士：黎明升起》之外，這位演員還曾經在另一部漫畫改編作品《萬惡城市：紅顏奪\n命》中飾演賭徒強尼，之後也參與了2020年的Netflix電影《超能計畫》。值得一提的是\n，喬瑟夫高登李維也曾親自執導過2013年的《超急情聖》，並找來了史嘉蕾喬韓森主演。 https://i.imgur.com/5C1RlcV.jpg 根據內線消息爆料者Charles Murphy的說法，喬瑟夫高登李維最近已經與至少一位來自凱\n文費吉旗下漫威工作室中的創意團隊成員取得過聯繫。但目前仍然無法確定這次的聯繫所\n談論的是潛在的角色演出邀約，或是加入幕後團隊的可能性。 https://i.imgur.com/Yl38SMW.jpg 有趣的是，這也並非喬瑟夫高登李維第一次傳出可能將要加入漫威系列的傳聞。近年來曾\n經有傳聞暗示將要由這位演員演出的角色包含了《星際異攻隊》的星爵、《蟻人》的史考\n特朗恩以及《奇異博士》的史蒂芬史傳奇，但這三位角色最終分別由克里斯普瑞特、保羅\n路德，以及班尼狄克康柏拜區飾演。\n\n\n即使多年下來一直有傳聞暗示諾蘭的蝙蝠俠宇宙在《黑暗騎士：黎明升起》之後可能將會\n由喬瑟夫高登李維繼續主演下去，但DC始終沒有證實相關的計畫。就在今年稍早，喬瑟夫\n高登李維在Reddit論壇的問答活動中提到他非常喜歡諾蘭《蝙蝠俠》三部曲的收尾方式。 https://i.imgur.com/mmAFIeC.jpg 爆料者Charles Murphy認為喬瑟夫高登李維與漫威的聯繫可能與《驚奇4超人》的重啟版\n本有關，這部讓粉絲們期待已久的新版本也已經在本月稍早的迪士尼投資者日上由凱文費\n吉本人親自揭露，並證實了將會由漫威版《蜘蛛人》三部曲導演強華茲負責執導，至於演\n員的部分則尚未公開。 https://i.imgur.com/97oE9bw.jpg 在這場最新的公開活動上，漫威工作室也揭露了第三部《蟻人》和《星際異攻隊》以及《\n驚奇隊長》續集的消息，以及預計的上映日期。至於未公開發行日期的則包含了《驚奇4\n超人》重啟版、馬赫夏拉阿里主演的《刀鋒戰士》重啟版，以及《月光騎士》、《女浩克\n》，再加上首度公開的《秘密入侵》(Secret Invasion)、《鋼鐵心》(Ironheart) 以及\n《裝甲戰爭》(Armor Wars)。 https://i.imgur.com/nzm2LuL.jpg 至於喬瑟夫高登李維，他的最新作品《7500》目前也正在Amazon Prime平台上熱播中，最\n近也演出了Netflix好評電影《芝加哥七人案：驚世審判》。而漫威工作室接下來的作品\n包含了將於2021年1月15日上線的《汪達與幻視》(WandaVision) 和5月7日的《黑寡婦》(\nBlack Widow)。 https://reurl.cc/8nQrQM 《汪達與幻視》最新短版預告： https://youtu.be/SntsSsMLUWA https://www.ptt.cc/bbs/movie/M.1609257932.A.2ED.html', 'ip': '49.216.129.155', 'message_count': {'all': 34, 'count': 24, 'push': 25, 'boo': 1, 'neutral': 8}, 'messages': [{'push_tag': '推', 'push_userid': 'aure0914', 'push_content': '想看他演羅賓', 'push_ipdatetime': '12/30 00:13'}, {'push_tag': '推', 'push_userid': 'REI3173', 'push_content': '慷仁', 'push_ipdatetime': '12/30 00:15'}, {'push_tag': '→', 'push_userid': 'uhawae', 'push_content': '還    蠻     屌     的      屌            爆', 'push_ipdatetime': '12/30 00:25'}, {'push_tag': '推', 'push_userid': 'alwaysstrong', 'push_content': '是要找他演李德？', 'push_ipdatetime': '12/30 00:34'}, {'push_tag': '推', 'push_userid': 'BleedWang', 'push_content': '他不夠狂 不可能演霹靂火 應該是演橡膠人無誤', 'push_ipdatetime': '12/30 00:36'}, {'push_tag': '→', 'push_userid': 'BleedWang', 'push_content': '但也有可能是石頭人啦', 'push_ipdatetime': '12/30 00:37'}, {'push_tag': '→', 'push_userid': 'takuminauki', 'push_content': '過氣二線', 'push_ipdatetime': '12/30 00:48'}, {'push_tag': '推', 'push_userid': 'BLUEPAPER', 'push_content': '不要再重啟了 根本浪費好演員', 'push_ipdatetime': '12/30 00:53'}, {'push_tag': '推', 'push_userid': 'kowei526', 'push_content': '想看他演羅賓+1 諾蘭都鋪好路了><', 'push_ipdatetime': '12/30 01:00'}, {'push_tag': '推', 'push_userid': 'alvis000', 'push_content': '我喜歡看他演戲', 'push_ipdatetime': '12/30 01:14'}, {'push_tag': '推', 'push_userid': 'd19901023', 'push_content': '結果是末日博士', 'push_ipdatetime': '12/30 01:26'}, {'push_tag': '推', 'push_userid': 'lucifax', 'push_content': '直接找吳慷仁比較快', 'push_ipdatetime': '12/30 01:26'}, {'push_tag': '→', 'push_userid': 'BoyoRo', 'push_content': '搞不好演隱形女啊', 'push_ipdatetime': '12/30 01:28'}, {'push_tag': '→', 'push_userid': 'MK47', 'push_content': '完全不會想看= =', 'push_ipdatetime': '12/30 02:00'}, {'push_tag': '噓', 'push_userid': 'Sk8erBoi', 'push_content': '.', 'push_ipdatetime': '12/30 02:58'}, {'push_tag': '推', 'push_userid': 'lost0816', 'push_content': '他的羅賓太棒，那個升起的結局，成為他演員最棒鏡頭', 'push_ipdatetime': '12/30 03:33'}, {'push_tag': '推', 'push_userid': 'Eddward', 'push_content': '是不是要開賭盤看這次4個哪個變黑人', 'push_ipdatetime': '12/30 03:51'}, {'push_tag': '推', 'push_userid': 'egg781', 'push_content': '不拍MCU版驚奇四超人你是要怎麼引入地獄博士,而且里', 'push_ipdatetime': '12/30 06:36'}, {'push_tag': '→', 'push_userid': 'egg781', 'push_content': '德還有搞砸揹鍋的作用', 'push_ipdatetime': '12/30 06:36'}, {'push_tag': '推', 'push_userid': 'lpb', 'push_content': '樓上，Dr.Doom應該是末日博士吧？XD', 'push_ipdatetime': '12/30 07:28'}, {'push_tag': '→', 'push_userid': 'lpb', 'push_content': '猜他應該是出演里德？', 'push_ipdatetime': '12/30 07:29'}, {'push_tag': '推', 'push_userid': 'sunsirr', 'push_content': '他之前演羅賓很適合，身材又好', 'push_ipdatetime': '12/30 07:40'}, {'push_tag': '推', 'push_userid': 'egg781', 'push_content': '更正末日博士,感謝', 'push_ipdatetime': '12/30 07:59'}, {'push_tag': '推', 'push_userid': 'litann4', 'push_content': '覺得他很帥', 'push_ipdatetime': '12/30 08:02'}, {'push_tag': '推', 'push_userid': 'peterw', 'push_content': '反而想看他演霹靂火耶，他看起來不夠聰明演李德', 'push_ipdatetime': '12/30 08:24'}, {'push_tag': '→', 'push_userid': 'wjack29', 'push_content': '美隊回鍋演霹靂火', 'push_ipdatetime': '12/30 08:29'}, {'push_tag': '推', 'push_userid': 'buwa56', 'push_content': '羅賓+1', 'push_ipdatetime': '12/30 08:33'}, {'push_tag': '推', 'push_userid': 'notea', 'push_content': '演李德或DOOM不錯阿', 'push_ipdatetime': '12/30 08:44'}, {'push_tag': '推', 'push_userid': 'FRX', 'push_content': '好喝到妹噗茶', 'push_ipdatetime': '12/30 08:51'}, {'push_tag': '推', 'push_userid': 'luke417', 'push_content': '美國吳慷仁', 'push_ipdatetime': '12/30 08:54'}, {'push_tag': '推', 'push_userid': 'maxiiiii', 'push_content': '他可以', 'push_ipdatetime': '12/30 09:01'}, {'push_tag': '推', 'push_userid': 'rinsoukan', 'push_content': '想看他演羅賓', 'push_ipdatetime': '12/30 09:15'}, {'push_tag': '推', 'push_userid': 'gogolamingo', 'push_content': '標題看成李登輝', 'push_ipdatetime': '12/30 10:05'}, {'push_tag': '推', 'push_userid': 'isislove', 'push_content': '小希斯～', 'push_ipdatetime': '12/30 10:11'}]}
2020-12-30 10:14:18 [scrapy.core.engine] INFO: Closing spider (finished)
2020-12-30 10:14:18 [PTTCrawler] DEBUG: Save result at /Users/hungyuchuan/Desktop/python-crawler/Day28/Day027_Scrapy_item/myproject/crawled_data/20201230T10:14:17-20201230T10:14:18.json
2020-12-30 10:14:18 [scrapy.extensions.feedexport] INFO: Stored json feed (2 items) in: ./output/Ptt.json
2020-12-30 10:14:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 850,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 12381,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 0.679103,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 12, 30, 2, 14, 18, 283324),
 'item_scraped_count': 2,
 'log_count/DEBUG': 7,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'memusage/max': 53178368,
 'memusage/startup': 53178368,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2020, 12, 30, 2, 14, 17, 604221)}
2020-12-30 10:14:18 [scrapy.core.engine] INFO: Spider closed (finished)
